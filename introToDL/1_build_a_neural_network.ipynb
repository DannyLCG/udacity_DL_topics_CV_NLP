{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f909c62",
   "metadata": {},
   "source": [
    "## Exercise: Build a Neural Network\n",
    "\n",
    "For this exercise, your task is to write code to build a neural network. The choice for the number of layers, and the number of neurons is up to you. However, since we will be using the MNIST dataset in this example, you will need to have 784 neurons in your input layer and 10 neurons in your output layer. Here are the steps you need to do:\n",
    "\n",
    "1. Create your model in the `create_model()` function.\n",
    "2. Return the model you created at the end of the function.\n",
    "\n",
    "**Note**: It may take 5 - 10 minutes to download the data sets. \n",
    "\n",
    "In case you get stuck, you can look at the solution notebook.\n",
    "\n",
    "### Try It Out!\n",
    "- Change the number of layers and neurons in your model. How does your model accuracy change? These values are called hyperparameters and they can change the performance of our model. In a later lesson, we will learn how to automatically search for hyperparameters that give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b50071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "def create_model():\n",
    "    # Set input and output size\n",
    "    input_size = 784\n",
    "    output_size = 10\n",
    "    model = nn.Sequential(nn.Linear(input_size, 128),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(128, 64),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(64, output_size),\n",
    "                         nn.LogSoftmax(dim=1)) #The function will be applied to each row of the input tensor\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf3cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Data\n",
      "Loading Model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(testset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m cost \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[1;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "File \u001b[0;32m/workspace/cd0387_intro_to_dl/1_build_a_neural_network/main.py:9\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m784\u001b[39m\n\u001b[1;32m      7\u001b[0m ouput_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mLinear(input_size, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m----> 9\u001b[0m                      \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRelu\u001b[49m(),\n\u001b[1;32m     10\u001b[0m                      nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m     11\u001b[0m                      nn\u001b[38;5;241m.\u001b[39mRelu(),\n\u001b[1;32m     12\u001b[0m                      nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     13\u001b[0m                      nn\u001b[38;5;241m.\u001b[39mLogSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#The function will be applied to each row of the input tensor\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Relu'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from main import create_model\n",
    "\n",
    "def train(model, train_loader, cost, optimizer, epoch):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        running_loss=0\n",
    "        correct=0\n",
    "        for data, target in train_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = cost(pred, target)\n",
    "            running_loss+=loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred=pred.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Set Hyperparameters\n",
    "batch_size=64\n",
    "epoch=10\n",
    "\n",
    "print(\"Downloading Data\")\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('data/', download=True, train=True, transform=training_transform)\n",
    "testset = datasets.MNIST('data/', download=True, train=False, transform=testing_transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Loading Model\")\n",
    "model=create_model()\n",
    "\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"Starting Model Training\")\n",
    "train(model, train_loader, cost, optimizer, epoch)\n",
    "print(\"Testing Trained Model\")\n",
    "test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce493a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
