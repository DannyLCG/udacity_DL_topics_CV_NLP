{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolutional Neural Network\n",
    "\n",
    "In this exercise, you will have to create a CNN model and then train it on the CIFAR10 dataset. The data loading and model training, testing logic are already included in your code. Infact, they are the same as for the Feed Forward Neural Network you built in the last exercises.\n",
    "\n",
    "Here are the steps you need to do to complete this exercise:\n",
    "\n",
    "1. In Starter Code below, finish the `Model()` class. These should contain the code that defines the layers of your model in the `__init__()` function and the model execution in the `forward()` function.\n",
    "2. Add a cost function and optimizer. You can use the same cost functions and optimizer from the previous exercise.\n",
    "3. Run the cells to make sure that the model is training properly.\n",
    "\n",
    "In case you get stuck, you can look at the solution by clicking the jupyter symbol at the top left and navigating to `training_a_cnn_solution.ipynb`.\n",
    "\n",
    "## Try It Out!\n",
    "- Play around with the number of layers and filters in your model. How does the accuracy change? How long does it take to train the model?\n",
    "- Try to train your model with some other types of convolutional layers like depthwise separable convolutions\n",
    "- Can you create the same network in TensorFlow as well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Installations\n",
    "**NOTE**: Everytime you start the GPU, run this before your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.display import HTML\n",
    "\n",
    "#HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code\n",
    "\n",
    "**Remember** to DISABLE the GPU when you are not training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =10\n",
    "\n",
    "# Define data transformations\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Download data\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=training_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=testing_transform)\n",
    "\n",
    "# Instance data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create a Model subclass from nn.Module\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super(Model, self).__init__()\n",
    "        super().__init__() #In Python 3.x, the super().__init__() call is enough\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) #OUT CHANNELS = NUMBER OF KERNELS\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #print(x.shape())\n",
    "        x = torch.flatten(x, 1) # Flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) #the activatio function is applied at training when calling the loss function!\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for e in range(1, epochs):\n",
    "        running_loss=0\n",
    "        correct=0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            #NOTE: Notice how we are not changing the data shape here\n",
    "            # This is because CNNs expects a 3 dimensional input\n",
    "            pred = model(data)\n",
    "            loss = loss_fn(pred, target)\n",
    "            running_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = pred.argmax(dim=1, keepdim=True) #get the predicted class\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() #count the number of correct predictions\n",
    "            # Accuracy = Correct predictions / All predictions ((TP + TN)/(All))\n",
    "        print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #NOTE: Notice how we are not changing the data shape here\n",
    "            # This is because CNNs expects a 3 dimensional input\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability (the predicted class)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() #count the number fo correct predictions\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model configs\n",
    "lr = 0.01\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Set model hyperparams\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,\n",
    "      train_loader,\n",
    "      loss_fn,\n",
    "      optimizer,\n",
    "      epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,\n",
    "     test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
