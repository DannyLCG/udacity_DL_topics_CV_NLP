{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf20a56",
   "metadata": {},
   "source": [
    "# Debugger and Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3940b",
   "metadata": {
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the parameters for the submitting script (this time we're working on a notebook to make it easier)\n",
    "\n",
    "hyperparameters = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"gpu\": True,\n",
    "    \"epoch\": 2,\n",
    "    \"model\": \"resnet50\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a821f4",
   "metadata": {},
   "source": [
    "#### Key concepts of Amazon SageMaker Debugger\n",
    "\n",
    "Amazon SageMaker Debugger lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Furthermore, it helps you monitor your training in near real time using rules and provides you alerts, once it has detected inconsistency in training flow.\n",
    "\n",
    "Concepts\n",
    "- Tensors: These represent the state of the training network at intermediate points during its execution\n",
    "- Debug Hook: Hook is the construct with which Amazon SageMaker Debugger looks into the training process and captures the tensors requested at the desired step intervals\n",
    "- Rule: A logical construct, implemented as Python code, which helps analyze the tensors captured by the hook and report anomalies, if at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775136c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "# Create debugging and profiling rules\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c377f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "\n",
    "# Instance profiler and debugger configs\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"})\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(num_stpes=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505436ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    base_job_name=\"smdebugger-cifar-pytorch\",\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    intance_count=1,\n",
    "    entry_point=\"scripts/pytorch_cifar_profiling.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_config,\n",
    "    rules=rules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31801190",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch the training job\n",
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06f89a",
   "metadata": {},
   "source": [
    "#### Prepare for debugging and profilinf analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1e438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62817f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9bf3b",
   "metadata": {},
   "source": [
    "## Checking Training Performance\n",
    "\n",
    "A Trial is an object used to interact with and analyze the debugging artifacts generated during a training job. SageMaker Debugger collects data such as tensors, metrics, and other relevant information at different points during the training process. These artifacts are stored in a specific path (e.g., in S3), and the Trial object allows you to access, query, and visualize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "# Instance the trial object\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85ab33",
   "metadata": {},
   "source": [
    "#### Print the names of tracked tensors for both train and evaluation, and the number of datapoints for each tnesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tensor names: {trial.tensor_names()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME THE TENSORS AS OUR MODEL USES CROSSENTROPY LOSS, NOT NLL LOSS\n",
    "print(f'Datapoints in the training tensor: {len(trial.tensor(\"nll_loss_output_0\").steps(mode=ModeKeys.TRAIN))}\\n')\n",
    "print(f'Datapoints in the evaluation tensor: {len(trial.tensor(\"nll_loss_output_0\").steps(mode=ModeKeys.EVAL))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6bceb2",
   "metadata": {},
   "source": [
    "### Plot the tracked tensors\n",
    "Set up functions to plot the output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrive the desired tensors by name\n",
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "# Def a function to plot the tensors\n",
    "def plot_tensor(trial, tensor_name):\n",
    "\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tensor(trial, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8eaa5f",
   "metadata": {},
   "source": [
    "## Check System Utilization\n",
    "\n",
    "The TrainingJob object tj encapsulates all the information and utilities required to interact with the profiling data collected during the specified training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02afe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08844661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "# Display system metrics\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0e9e5",
   "metadata": {},
   "source": [
    "## Display the Profiler Report\n",
    "We will fetch the profiler report from the S3 bucket where it was stored and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab2a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report at {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd665fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp {rule_output_path} ./ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
